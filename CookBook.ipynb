{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "radical-disposition",
   "metadata": {},
   "source": [
    "# Step-by-step manual :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-jacob",
   "metadata": {},
   "source": [
    "## Building Mock maps :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-tennis",
   "metadata": {},
   "source": [
    "### Mock spectra :\n",
    "\n",
    "1. Run fake_spectra in parallel on TNG :\n",
    "\n",
    "\n",
    "- First, we need to calculate required number of sightlines. It scales number of sightliens in LATIS to TNG300-1 cross section. The function below, takes the 3 data file from LATIS, which are the pixfile, mapfile and idsfile. \n",
    "\n",
    "The output is the number of random spectra we need to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sharing-listing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6738.573846169163"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import codes.spectra_mocking as sm\n",
    "sm.get_mock_sightline_number(pixfile='../spectra/maps/mapsv13/dcv13pix.dat', \n",
    "                             mapfile='../spectra/maps/mapsv13/dcv13map.dat',\n",
    "                             idsfile='../spectra/maps/mapsv13/dcv13ids.dat', \n",
    "                             z_range=[2.4,2.6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-joint",
   "metadata": {},
   "source": [
    "**Note:** These 3 observed data file are not publicly available yet. The only thing we need from those data are sightline densities at each redshift. So, you can skip the next cell and use the table below summarizing the sightline densities:\n",
    "\n",
    "| z | required spectra in TNG300-1 |\n",
    "| --| ---------------------------- |\n",
    "| 2.3 | 9017 |\n",
    "| 2.45 | 6739 |\n",
    "| 2.6 | 4409 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-administration",
   "metadata": {},
   "source": [
    "- Second we should set a small spectral resolution for our spectra, `res` argument in `fake_spectra`. \n",
    "\n",
    "  I have set it as   `res = detector resolution / 10`   , so later by averaging over the flux within 10 adjacent pixels, we'll get the spectra with detector's resolution. This is closer to what being **observationally measured** compared to summing up the optical depth across all pixels which would have been calculated if we had set the `res = detector resolution` . \n",
    "  \n",
    "\n",
    "How to get detector and spectral resolutions ? They are the outputs here, respectively in the tuple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "offensive-luxury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129.03335557027032, 147.6715069304205)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.get_spec_res(z=2.4442257045541464)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-indiana",
   "metadata": {},
   "source": [
    "**Note :** For the cell above and for anything from here, you do not need the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-bangladesh",
   "metadata": {},
   "source": [
    "Now, we pass the sightline number and resolution to `fake_Spectra.rand_spectra()`. There are some samples of submit files [here](https://github.com/mahdiqezlou/LyTomo-Watershed/tree/main/helper_scripts/generate_spectra) which call the helper code [here](https://github.com/mahdiqezlou/LyTomo-Watershed/blob/main/helper_scripts/generate_spectra/parallel_spectra.py) to run fake_spectra in MPI.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. Add noise and prepare for `dashchund` :\n",
    "\n",
    "To add noise and write the spectra in a format readable to `dashchund`, run this code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ethical-dancing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dvbin =  6.463172825361224\n",
      "7832  sightlines. resolution:  6.463172825361224  z= 2.4442257045541464\n",
      "dvbin =  6.463172825361224\n",
      "7832  sightlines. resolution:  6.463172825361224  z= 2.4442257045541464\n",
      "mean flux after noise = 0.8202996281424243\n",
      "*** Error on mean flux :***  0.009905708551735004\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(sm)\n",
    "sm.write_input_dachshund_v2(spec_res=147.6715069304205, addpix=20,\n",
    "                            savefile='../LyTomo_data/spectra_z2.4/spectra_TNG_z2.4_n1.hdf5', \n",
    "                            output_file='../LyTomo_data/pix_files/pix_TNG_z2.4_n1.dat', \n",
    "                            add_CE=True, add_CNR=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-break",
   "metadata": {},
   "source": [
    "### Run `dashchund` :\n",
    "\n",
    "We have made dashchund output in last step. Now, we should make a config file which dashchund reads instruction from. That file looks like this, an explanation for each field is added after the # sign, remove them before running the dashchund :\n",
    "\n",
    "```\n",
    "lx = 205 # map size in cMpc/h\n",
    "ly = 205\n",
    "lz = 205\n",
    "num_pixels = 1284579 # this is size of the pix file divided by 5\n",
    "map_nx = 205  # number of pixels\n",
    "map_ny = 205\n",
    "map_nz = 205\n",
    "corr_var_s = 0.05\n",
    "corr_l_perp = 2.5\n",
    "corr_l_para = 2.1\n",
    "pcg_tol = 1.0e-3\n",
    "pcg_max_iter = 100\n",
    "pixel_data_path = ./pixel_files/pix_TNG_z2.4_averageF.dat\n",
    "map_path = ./maps/map_TNG_z2.4.dat\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-tobago",
   "metadata": {},
   "source": [
    "Next we can run `dashchund` with : `dashchund.exe TNG_z2.4_n1_DCV13.cfg`. Or you can find a submission sample [here](https://github.com/mahdiqezlou/LyTomo-Watershed/helper_scripts/dachshund/submit) . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-reset",
   "metadata": {},
   "source": [
    "## DM density field :\n",
    "\n",
    "You need a dark matter density field on a regular grid for the next session when calculating the DM masses of the strucutres.\n",
    "\n",
    "1. You can use the `TNG()` method [here](https://github.com/mahdiqezlou/LyTomo-Watershed/blob/main/codes/get_density_field.py) to get that in an MPI fassion. The sample script to run with is [here](https://github.com/mahdiqezlou/LyTomo-Watershed/blob/main/helper_scripts/DensityField/run_get_densityfield.py).\n",
    "\n",
    "2. `TNG()` method writes down the outcome of each rank on an individual file, you need to use `LATIS.codes.get_density_field.make_full_mesh()` to add up the files. This is a serial code and already very quick."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-climb",
   "metadata": {},
   "source": [
    "## Strucutres:\n",
    "\n",
    "Now, we need to find the strucutres within the mock map. For this, we need mock map, true map and DM density map. \n",
    "\n",
    "To find the optimal `peak threshold` value. Use the script [here](https://github.com/mahdiqezlou/LyTomo-Watershed/blob/main/helper_scripts/watershed_params/thresh/get_th_parallel.py) to find these structures for a wide range of `peak threshold`. I run this MPI code in 3 chuncks of peak threshold ranges, $[2.0,2.25] - [2.3,2.55] - [2.6,2.85]$.\n",
    "\n",
    "\n",
    "The outputs for each `peak threshold` are 2 files, one containing info such as tomography mass for all subregions and the other a file containing all contours defining the volume of subregions (label maps).\n",
    "\n",
    "- To select the optimal watershed parametes, the island threshold significance, $\\nu$, and the absorption peak significance, $\\kappa$, look at [this notebook](https://github.com/mahdiqezlou/LyTomo-Watershed/blob/main/select_kappa_nu.ipynb).\n",
    "\n",
    "- To justify the selection of the parameters above and generally the watershed method, look at [this notebook](https://github.com/mahdiqezlou/LyTomo-Watershed/blob/main/justify_watershed.ipynb)\n",
    "\n",
    "- To provide an estimator on the Dark matter mass within these watersheds take a look at [this notebook](https://github.com/mahdiqezlou/LyTomo-Watershed/blob/main/MDM_Mtomo.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-cartridge",
   "metadata": {},
   "source": [
    "## Connection to z =0 :\n",
    "\n",
    "In this step, we connect all structures to a FOF halo zt z=0. \n",
    "\n",
    "\n",
    "1.  we find all halos within each subregion. For this, use `highz_halos()` in `LATIS/codes/halos.py`. It is an MPI code, so you can run it using [this sample script](https://github.com/mahdiqezlou/LyTomo-Watershed/blob/main/helper_scripts/descendants/run_find_halos.py) with a\n",
    "\n",
    "\n",
    "2. Now we find the root subhalo descendant of the FirstSubhalo of all the halos within each subregion. It records lot's of info including the `SubhaloGrNr` which is the group number of the descendant subhalo. To do so, in `LATIS/codes/descendant.py` , we call `find_roots()`.  This code is MPI-parallel, you cnan use [this](https://github.com/mahdiqezlou/LyTomo-Watershed/blob/main/helper_scripts/descendants/run_find_roots.py) smaple script to run it.\n",
    "\n",
    "\n",
    "3. Now, all halos within a subregion vote for the FOF parent halos of the descendant subhalos . The votes are weighted by the mass of the halos at high-z. For this we use `find_voted_FOF_roots()` in `descendant.py`. This is also MPI-Parallel and you can use [this](https://github.com/mahdiqezlou/LyTomo-Watershed/blob/main/helper_scripts/descendants/run_find_voted_FOF_roots.py) example script to run it.\n",
    "\n",
    "\n",
    "- After creating this map between watersheds at z=2.5 and halos at z=0, take a look at [this notebook](https://github.com/mahdiqezlou/LyTomo-Watershed/blob/main/M0_Mtomo.ipynb) to provide an estimator for the descendant mass of each watershed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-corrections",
   "metadata": {},
   "source": [
    "## Progenitors :\n",
    "\n",
    "In some cases in our paper, we needed the progenitors of the massive z=0 halos. The progenitors are found by tracing all DM particles within R200 of z=0 halos back to z=2.5. \\\n",
    "The core code is `./codes/progenitors_particles.py` Which has methods for :\n",
    "\n",
    "1. Find the massive z=0 halos above a mass threshold. `get_clusters_low_z()`\n",
    "2. Find the IDs of the particles within their R200 radius of each of the halos. `get_center_part_IDs`\n",
    "3. Trace those particles to z=2.5 and find their coordinates at that snapshot and make a density map for (i.e. $\\rho_{DM} / <\\rho_{DM}>$) from the progenitor particles for each halo. `get_part_coord_parallel`\n",
    "4. We often use the center of mass for these progenitors. You can get it with `get_cofm()`\n",
    "\n",
    "Some of these methods are MPI and hence very efficient. For running `get_part_coord_parallel()`, we provide a helper script [here](https://github.com/mahdiqezlou/LyTomo-Watershed/blob/main/helper_scripts/progenitors/progenitor_parallel.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-vehicle",
   "metadata": {},
   "source": [
    "## FGPA :\n",
    "\n",
    "To generate spectra and mock maps with fluctuating Gunn-Peterson approximation (FGPA), you need ti use the `codes/fgpa.py` code [here](https://github.com/mahdiqezlou/LyTomo-Watershed/blob/main/codes/fgpa.py) . Below is a copy of the documentaion on that code :\n",
    "\n",
    "Generating spectra with Fluctuating Gunn Peterson Approximation (FGPA)\n",
    "\n",
    "- The code is MPI working on Illustris and MP-Gadget snapshots. The packages needed are :\n",
    "\n",
    "    - astropy \n",
    "    - fake_spectra\n",
    "\n",
    "To get the FGPA spectra, follow the steps below :\n",
    "\n",
    "1. From `codes.get_density`_field use TNG() or MP-Gadget() to construct DM density\n",
    "   field on a grid with desired size. For FGPA, the grid cells should on avergae \n",
    "   have 1 particle per cell.\n",
    "  \n",
    "2. Save the results from the previous step in savedir directory. The density \n",
    "   has been saved on several files depending on number of ranks used. \n",
    "\n",
    "3. Run `get_noiseless_map()` or `get_sample_spectra()` functions here with the same\n",
    "   number of MPI ranks and pass the directories for the density field above as \n",
    "   savedir argument. \n",
    "\n",
    "4. The output is a single hdf5 file containing either the full true flux map or the\n",
    "   random spectra sample. Note : In case your desired map is too large to fit on your \n",
    "   memory, modify the last lines of the functions to store results of each rank separately. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
